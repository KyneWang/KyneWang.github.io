<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://kynewang.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://kynewang.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-05-22T13:05:45+00:00</updated><id>https://kynewang.github.io/feed.xml</id><title type="html">Homepage of Dr. Kai Wang</title><subtitle>Kai Wang obtained his Bachelor, Master, Doctor degrees in Software Engineering from Dalian University of Technology, Dalian, P.R. China in 2015, 2019 and 2022 respectively. Kai submitted his Cotutelle Ph.D. thesis at the School of Computing, Macquarie University supervised by Prof. Dr. Michael Sheng in 2022. Kai is currently a postdoctoral research fellow at Nanyang Technological University, Singapore. Kai&apos;s research interests include, but are not limited to, Knowledge Graph Reasoning, Graph Neural Networks, and Large Language Models. He has published a number of papers at the top conferences and journals of these research areas, i.e., VLDB, ACL, KDD, IJCAI, EMNLP, and the Web Conference. </subtitle><entry><title type="html">Three papers accepted by top confs</title><link href="https://kynewang.github.io/blog/2024/PaperAccepted/" rel="alternate" type="text/html" title="Three papers accepted by top confs"/><published>2024-05-17T20:32:13+00:00</published><updated>2024-05-17T20:32:13+00:00</updated><id>https://kynewang.github.io/blog/2024/PaperAccepted</id><content type="html" xml:base="https://kynewang.github.io/blog/2024/PaperAccepted/"><![CDATA[<h2 id="paper-acceptance-in-may-2024">Paper Acceptance in May 2024</h2> <p>Thrilled to share that our major research projects from last year have been accepted by VLDB, ACL, and KDD conferences!</p> <p>The PVLDB paper focuses on storage optimization for large-scale subgraph extraction; the ACL work leverages large language models to enhance graph inductive reasoning; and the KDD project achieves efficient contrastive learning on dynamic graphs.</p> <p>Many thanks to Prof. Luo and all our co-authors for their hard work and dedication!</p> <p>Welcome collaboration and feedback from our peers and look forward to further exploration in large-scale graph models and graph-enhanced LLMs.</p>]]></content><author><name></name></author><category term="paper"/><category term="acceptance"/><category term="paper"/><category term="acceptance"/><summary type="html"><![CDATA[paper acceptance by VLDB, ACL and KDD]]></summary></entry><entry><title type="html">Displaying External Posts on Your al-folio Blog</title><link href="https://kynewang.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/" rel="alternate" type="text/html" title="Displaying External Posts on Your al-folio Blog"/><published>2022-04-23T23:20:09+00:00</published><updated>2022-04-23T23:20:09+00:00</updated><id>https://kynewang.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog</id><content type="html" xml:base="https://kynewang.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/"><![CDATA[]]></content><author><name></name></author></entry></feed>