<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://kynewang.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://kynewang.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-05-23T07:33:28+00:00</updated><id>https://kynewang.github.io/feed.xml</id><title type="html">Kai Wangâ€™s Homepage</title><subtitle>Kai Wang is currently a postdoctoral research fellow at Nanyang Technological University, Singapore. He obtained his Ph.D. degrees from Macquarie University, Australia and Dalian University of Technology, P.R. China in 2022, and obtained his Bachelor, Master degrees in Software Engineering from Dalian University of Technology in 2015 and 2019 respectively. Kai&apos;s research interests include, but are not limited to, Knowledge Graph Reasoning, Graph Neural Networks, and Large Language Models. He has published a number of papers at the top conferences and journals of these research areas, i.e., VLDB, ACL, KDD, IJCAI, EMNLP, and the Web Conference. </subtitle><entry><title type="html">Three Papers Accepted by Top Confs</title><link href="https://kynewang.github.io/blog/2024/PaperAccepted/" rel="alternate" type="text/html" title="Three Papers Accepted by Top Confs"/><published>2024-05-17T20:32:13+00:00</published><updated>2024-05-17T20:32:13+00:00</updated><id>https://kynewang.github.io/blog/2024/PaperAccepted</id><content type="html" xml:base="https://kynewang.github.io/blog/2024/PaperAccepted/"><![CDATA[<h2 id="paper-acceptance-in-may-2024">Paper Acceptance in May 2024</h2> <p>Thrilled to share that our major research projects from last year have been accepted by VLDB, ACL, and KDD conferences!</p> <p>The PVLDB paper focuses on storage optimization for large-scale subgraph extraction; the ACL work leverages large language models to enhance graph inductive reasoning; and the KDD project achieves efficient contrastive learning on dynamic graphs.</p> <p>Many thanks to Prof. Luo and all our co-authors for their hard work and dedication!</p> <p>Welcome collaboration and feedback from our peers and look forward to further exploration in large-scale graph models and graph-enhanced LLMs.</p>]]></content><author><name></name></author><category term="paper"/><category term="paper"/><summary type="html"><![CDATA[Paper Acceptance by VLDB, ACL and KDD]]></summary></entry></feed>